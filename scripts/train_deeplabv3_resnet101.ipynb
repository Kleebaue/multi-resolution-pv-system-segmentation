{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1471b281-bbc8-43f8-b6ad-6cc59bdc9779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the script can be used to train the networks within the publication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2674e496-5c91-4dd1-9152-c5a9c65224fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F, ToTensor, InterpolationMode\n",
    "import torchvision.models as models\n",
    "from torchvision.models.segmentation import deeplabv3_resnet101, DeepLabV3_ResNet101_Weights \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, root_dirs, resize=256, crop_size=256):\n",
    "        self.root_dirs = root_dirs\n",
    "        self.image_dirs = [os.path.join(root_dir, 'image') for root_dir in root_dirs]\n",
    "        self.mask_dirs = [os.path.join(root_dir, 'mask') for root_dir in root_dirs]\n",
    "        self.image_filenames = self.collect_image_filenames()\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.CenterCrop(crop_size),\n",
    "            transforms.Resize([resize], interpolation=InterpolationMode.BILINEAR),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def collect_image_filenames(self):\n",
    "        image_filenames = []\n",
    "        for image_dir in self.image_dirs:\n",
    "            image_filenames += os.listdir(image_dir)\n",
    "        return image_filenames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_filenames[idx]\n",
    "        image_path = self.find_image_path(image_name)\n",
    "        mask_path = self.find_mask_path(image_name)\n",
    "\n",
    "        image = self.load_image(image_path)\n",
    "        mask = self.load_mask(mask_path)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def find_image_path(self, image_name):\n",
    "        for image_dir in self.image_dirs:\n",
    "            image_path = os.path.join(image_dir, image_name)\n",
    "            if os.path.exists(image_path):\n",
    "                return image_path\n",
    "        raise FileNotFoundError(f\"Image file not found: {image_name}\")\n",
    "\n",
    "    def find_mask_path(self, image_name):\n",
    "        for mask_dir in self.mask_dirs:\n",
    "            mask_path = os.path.join(mask_dir, image_name)\n",
    "            if os.path.exists(mask_path):\n",
    "                return mask_path\n",
    "        raise FileNotFoundError(f\"Mask file not found: {image_name}\")\n",
    "\n",
    "    def load_image(self, path):\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        image = self.transforms(image)\n",
    "        return image\n",
    "\n",
    "    def load_mask(self, path):\n",
    "        mask = Image.open(path).convert('L')\n",
    "        mask = self.transforms(mask)\n",
    "        mask = torch.squeeze(mask, dim=0)  # Squeeze the mask\n",
    "        return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb819529-6c94-411d-a9ad-b7a2656313ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "\n",
    "if use_cuda and not torch.cuda.is_available():\n",
    "    print(\"Error: cuda requested but not available, will use cpu instead!\")\n",
    "    device = torch.device('cpu')\n",
    "elif not use_cuda:\n",
    "    print(\"Info: will use cpu!\")\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    print(f\"Info: Devices: {torch.cuda.device_count()} {torch.cuda.get_device_name(0)} GPU available, will use gpu!\")\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "print(f\"Number of CPU cores: {os.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c37f1-49aa-4156-b1c1-befc79f54194",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fixed parameters\n",
    "batch_size = 16\n",
    "learning_rate = 0.00001\n",
    "epochs = 100\n",
    "\n",
    "dataset_path = '/share/data1/pv_segmentation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb0e6cb-a5e1-430d-8ff3-87ee3f5bf1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_masks_predictions(images, masks, predicted_masks):\n",
    "    batch_size = images.shape[0]\n",
    "    fig, axs = plt.subplots(batch_size, 3, figsize=(15, 5*batch_size))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Plot the image\n",
    "        axs[i, 0].imshow(images[i].transpose(1, 2, 0))\n",
    "        axs[i, 0].set_title('Image {}'.format(i+1))\n",
    "        axs[i, 0].axis('off')\n",
    "\n",
    "        # Plot the ground truth mask\n",
    "        axs[i, 1].imshow(masks[i], cmap='gray')\n",
    "        axs[i, 1].set_title('Ground Truth Mask {}'.format(i+1))\n",
    "        axs[i, 1].axis('off')\n",
    "   \n",
    "        predicted_mask = predicted_masks[i]\n",
    "        if predicted_mask.ndim == 2:\n",
    "            axs[i, 2].imshow(predicted_mask, cmap='gray')\n",
    "        elif predicted_mask.ndim == 3:\n",
    "            axs[i, 2].imshow(predicted_mask.transpose(1, 2, 0))\n",
    "        else:\n",
    "            raise ValueError('Invalid shape of predicted mask')\n",
    "        axs[i, 2].set_title('Predicted Mask {}'.format(i+1))\n",
    "        axs[i, 2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def test_segmentation_network(model, dataloader):\n",
    "    # Get a batch of images and masks\n",
    "    images, masks = next(iter(dataloader))\n",
    "\n",
    "    # Move images and masks to the device\n",
    "    device = next(model.parameters()).device\n",
    "    images = images.to(device)\n",
    "    masks = masks.to(device)\n",
    "\n",
    "    # Run the model to get the predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)['out']\n",
    "        predictions = torch.sigmoid(outputs).cpu().numpy()\n",
    "\n",
    "    # Convert tensors to numpy arrays\n",
    "    images = images.cpu().numpy()\n",
    "    masks = masks.cpu().numpy()\n",
    "\n",
    "    plot_images_masks_predictions(images, masks, predicted_masks)\n",
    "\n",
    "    \n",
    "def plot_batch(dataloader,batch_size):\n",
    "    # Get a batch of images and masks\n",
    "    images, masks = next(iter(dataloader))\n",
    "\n",
    "    # Convert tensors to numpy arrays\n",
    "    images = images.numpy()\n",
    "    masks = masks.numpy()\n",
    "\n",
    "    # Plot the images and masks\n",
    "    fig, axs = plt.subplots(batch_size, 2, figsize=(10, 5*batch_size))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Plot the image\n",
    "        axs[i, 0].imshow(images[i].transpose(1, 2, 0))\n",
    "        axs[i, 0].set_title('Image {}'.format(i+1))\n",
    "        axs[i, 0].axis('off')\n",
    "\n",
    "        # Plot the mask\n",
    "        axs[i, 1].imshow(masks[i], cmap='gray')\n",
    "        axs[i, 1].set_title('Mask {}'.format(i+1))\n",
    "        axs[i, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()   \n",
    "    \n",
    "# import metrics\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryRecall, BinaryPrecision, BinaryF1Score, BinaryJaccardIndex\n",
    "calculate_accuracy = BinaryAccuracy()\n",
    "calculate_precision = BinaryPrecision()\n",
    "calculate_recall = BinaryRecall()\n",
    "calculate_f1_score = BinaryF1Score()\n",
    "calculate_iou = BinaryJaccardIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c0198-acc3-45a5-b917-1215e0ed3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare model\n",
    "def load_model():\n",
    "    model = models.segmentation.deeplabv3_resnet101(weights=DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1)\n",
    "    model.backbone.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    num_classes = 1  # Assuming binary segmentation (1 class)\n",
    "    model.classifier = models.segmentation.deeplabv3.DeepLabHead(2048, num_classes)\n",
    "\n",
    "        # Set up the device (CPU or GPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e62eb7-366b-452b-ac49-dfdba954dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def train_segmentation_network(model, dataset, dataset_eval, num_epochs, batch_size, learning_rate, save_path, log_dir, dataset_paths):\n",
    "    \"\"\"Trains a segmentation network using the provided dataset and saves the trained model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.model): The model for training\n",
    "        dataset (torch.utils.data.Dataset): The dataset for training.\n",
    "        num_epochs (int): The number of training epochs.\n",
    "        batch_size (int): The batch size for training.\n",
    "        learning_rate (float): The learning rate for optimization.\n",
    "        save_path (str): The file path to save the trained model.\n",
    "        log_dir (str): The directory path to save the TensorBoard logs.\n",
    "\n",
    "    \"\"\"\n",
    "    # Instantiate the DeepLabV3_ResNet101 model with pretrained weights\n",
    "   \n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Create the data loader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Create the data loader for evaluation\n",
    "    eval_dataloader = DataLoader(dataset_eval, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Set up TensorBoard writer\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "\n",
    "        for images, masks in dataloader:\n",
    "            # Move images and masks to the device\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)['out']\n",
    "            outputs = torch.squeeze(outputs)  # Remove the extra dimensions\n",
    "\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataset)\n",
    "        print('Loss: {:.4f}'.format(epoch_loss))\n",
    "\n",
    "        best_iou = 0.0  # Variable to track the highest IoU\n",
    "        \n",
    "        # Evaluate the model and plot the images, masks, and predicted masks every 10th epoch\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                accuracy_list = []\n",
    "                precision_list = []\n",
    "                recall_list = []\n",
    "                f1_score_list = []\n",
    "                iou_list = []\n",
    "\n",
    "                for images, masks in eval_dataloader:\n",
    "                    images = images.to(device)\n",
    "                    masks = masks.to(device)\n",
    "\n",
    "                    outputs = model(images)['out']\n",
    "                    predicted_masks = torch.sigmoid(outputs) > 0.5\n",
    "\n",
    "                    images = images.cpu()\n",
    "                    masks = masks.cpu()\n",
    "                    predicted_masks = predicted_masks.cpu()\n",
    "\n",
    "                    threshold = 0.5\n",
    "                    mask = (masks >= threshold).int()\n",
    "                    predicted_mask = (predicted_masks >= threshold).int()\n",
    "\n",
    "                    accuracy = calculate_accuracy(predicted_mask.squeeze(), mask)\n",
    "                    precision = calculate_precision(predicted_mask.squeeze(), mask)\n",
    "                    recall = calculate_recall(predicted_mask.squeeze(), mask)\n",
    "                    f1_score = calculate_f1_score(predicted_mask.squeeze(), mask)\n",
    "                    iou = calculate_iou(predicted_mask.squeeze(), mask)\n",
    "\n",
    "                    accuracy_list.append(accuracy)\n",
    "                    precision_list.append(precision)\n",
    "                    recall_list.append(recall)\n",
    "                    f1_score_list.append(f1_score)\n",
    "                    iou_list.append(iou)\n",
    "\n",
    "                # Calculate average metrics\n",
    "                avg_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "                avg_precision = sum(precision_list) / len(precision_list)\n",
    "                avg_recall = sum(recall_list) / len(recall_list)\n",
    "                avg_f1_score = sum(f1_score_list) / len(f1_score_list)\n",
    "                avg_iou = sum(iou_list) / len(iou_list)\n",
    "\n",
    "                # Print average evaluation metrics\n",
    "                print('Accuracy: {:.4f}'.format(avg_accuracy))\n",
    "                print('Precision: {:.4f}'.format(avg_precision))\n",
    "                print('Recall: {:.4f}'.format(avg_recall))\n",
    "                print('F1 Score: {:.4f}'.format(avg_f1_score))\n",
    "                print('IoU: {:.4f}'.format(avg_iou))\n",
    "\n",
    "                # Write average validation metrics to TensorBoard\n",
    "                writer.add_scalar('Accuracy', avg_accuracy, epoch)\n",
    "                writer.add_scalar('Precision', avg_precision, epoch)\n",
    "                writer.add_scalar('Recall', avg_recall, epoch)\n",
    "                writer.add_scalar('F1 Score', avg_f1_score, epoch)\n",
    "                writer.add_scalar('IoU', avg_iou, epoch)\n",
    "\n",
    "                # Plot the images, masks, and predicted masks\n",
    "                # plot_images_masks_predictions(images.numpy(), masks.numpy(), predicted_masks.numpy())\n",
    "\n",
    "                # Save the trained model\n",
    "\n",
    "                if avg_iou > best_iou:\n",
    "                    best_iou = avg_iou\n",
    "                    file_list = [path.split('/')[-1] for path in dataset_paths]\n",
    "                    marker = '_'.join(file_list)\n",
    "                    torch.save(model, save_path + \"/model_\" + str(marker) + \".pt\")\n",
    "                    print('Model saved to:', save_path)\n",
    "\n",
    "    # Save the TensorBoard writer\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    print('TensorBoard writer saved to:', log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc3550-af11-4b9c-9aeb-7c00780ea020",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path1 = '/share/data1/pv_segmentation/PV01_train'\n",
    "dataset_path2 = '/share/data1/pv_segmentation/PV02_train'\n",
    "dataset_path3 = '/share/data1/pv_segmentation/PV03_train'\n",
    "dataset_path4 = '/share/data1/pv_segmentation/PV08_train'\n",
    "dataset_path5 = '/share/data1/pv_segmentation/PV16_train'\n",
    "dataset_path6 = '/share/data1/pv_segmentation/PV32_train'\n",
    "\n",
    "val_path1 = '/share/data1/pv_segmentation/PV01_val'\n",
    "val_path2 = '/share/data1/pv_segmentation/PV02_val'\n",
    "val_path3 = '/share/data1/pv_segmentation/PV03_val'\n",
    "val_path4 = '/share/data1/pv_segmentation/PV08_val'\n",
    "val_path5 = '/share/data1/pv_segmentation/PV16_val'\n",
    "val_path6 = '/share/data1/pv_segmentation/PV32_val'\n",
    "\n",
    "save_path = dataset_path \n",
    "log_dir = dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bbe12d-06eb-4306-b517-57ea6aed014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. run\n",
    "dataset_paths = [dataset_path1]\n",
    "#dataset_paths = [dataset_path1, dataset_path2, dataset_path3]\n",
    "dataset = SegmentationDataset(dataset_paths)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_path_eval = [val_path1]\n",
    "dataset_eval = SegmentationDataset(dataset_path_eval)\n",
    "dataloader_eval = torch.utils.data.DataLoader(dataset_eval, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = load_model()\n",
    "train_segmentation_network(model, dataset, dataset_eval, epochs, batch_size, learning_rate, save_path, log_dir, dataset_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d283eb1-75f6-43f7-8a52-e9693d600c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. run\n",
    "dataset_paths = [dataset_path2]\n",
    "#dataset_paths = [dataset_path1, dataset_path2, dataset_path3]\n",
    "dataset = SegmentationDataset(dataset_paths)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_path_eval = [val_path2]\n",
    "dataset_eval = SegmentationDataset(dataset_path_eval)\n",
    "dataloader_eval = torch.utils.data.DataLoader(dataset_eval, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = load_model()\n",
    "train_segmentation_network(model, dataset, dataset_eval, epochs, batch_size, learning_rate, save_path, log_dir, dataset_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a3228-dc57-4d4d-8c94-09fc605cde7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. run\n",
    "dataset_paths = [dataset_path3]\n",
    "\n",
    "dataset = SegmentationDataset(dataset_paths)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_path_eval = [val_path3]\n",
    "dataset_eval = SegmentationDataset(dataset_path_eval)\n",
    "dataloader_eval = torch.utils.data.DataLoader(dataset_eval, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = load_model()\n",
    "train_segmentation_network(model, dataset, dataset_eval, epochs, batch_size, learning_rate, save_path, log_dir, dataset_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e67f97-24bf-4514-b3a9-f10ff1404624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. run\n",
    "dataset_paths = [dataset_path4]\n",
    "#dataset_paths = [dataset_path1, dataset_path2, dataset_path3]\n",
    "dataset = SegmentationDataset(dataset_paths)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_path_eval = [val_path4]\n",
    "dataset_eval = SegmentationDataset(dataset_path_eval)\n",
    "dataloader_eval = torch.utils.data.DataLoader(dataset_eval, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = load_model()\n",
    "train_segmentation_network(model, dataset, dataset_eval, epochs, batch_size, learning_rate, save_path, log_dir, dataset_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc7db3-d744-43bd-bb99-95196ad8a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = [dataset_path5]\n",
    "#dataset_paths = [dataset_path1, dataset_path2, dataset_path3]\n",
    "dataset = SegmentationDataset(dataset_paths)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_path_eval = [val_path5]\n",
    "dataset_eval = SegmentationDataset(dataset_path_eval)\n",
    "dataloader_eval = torch.utils.data.DataLoader(dataset_eval, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = load_model()\n",
    "train_segmentation_network(model, dataset, dataset_eval, epochs, batch_size, learning_rate, save_path, log_dir, dataset_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92eafcc-1d2c-4d30-aac9-b5a2e6d9ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = [dataset_path6]\n",
    "#dataset_paths = [dataset_path1, dataset_path2, dataset_path3]\n",
    "dataset = SegmentationDataset(dataset_paths)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_path_eval = [val_path6]\n",
    "dataset_eval = SegmentationDataset(dataset_path_eval)\n",
    "dataloader_eval = torch.utils.data.DataLoader(dataset_eval, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = load_model()\n",
    "train_segmentation_network(model, dataset, dataset_eval, epochs, batch_size, learning_rate, save_path, log_dir, dataset_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab79a65-4d47-42de-a85d-0e34e390e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = [dataset_path1,dataset_path2]\n",
    "#dataset_paths = [dataset_path1, dataset_path2, dataset_path3]\n",
    "dataset = SegmentationDataset(dataset_paths)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_path_eval = [val_path1]\n",
    "dataset_eval = SegmentationDataset(dataset_path_eval)\n",
    "dataloader_eval = torch.utils.data.DataLoader(dataset_eval, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = load_model()\n",
    "train_segmentation_network(model, dataset, dataset_eval, epochs, batch_size, learning_rate, save_path, log_dir, dataset_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdd4695-8a2f-4181-9b9c-2a4596a87119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. run\n",
    "dataset_paths = [dataset_path1,dataset_path2,dataset_path3]\n",
    "#dataset_paths = [dataset_path1, dataset_path2, dataset_path3]\n",
    "dataset = SegmentationDataset(dataset_paths)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_path_eval = [val_path1]\n",
    "dataset_eval = SegmentationDataset(dataset_path_eval)\n",
    "dataloader_eval = torch.utils.data.DataLoader(dataset_eval, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = load_model()\n",
    "train_segmentation_network(model, dataset, dataset_eval, epochs, batch_size, learning_rate, save_path, log_dir, dataset_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc6e268-d44b-46f9-94e6-3deb0bbb41a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. run\n",
    "dataset_paths = [dataset_path1,dataset_path2,dataset_path3,dataset_path4]\n",
    "#dataset_paths = [dataset_path1, dataset_path2, dataset_path3]\n",
    "dataset = SegmentationDataset(dataset_paths)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_path_eval = [val_path1]\n",
    "dataset_eval = SegmentationDataset(dataset_path_eval)\n",
    "dataloader_eval = torch.utils.data.DataLoader(dataset_eval, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = load_model()\n",
    "train_segmentation_network(model, dataset, dataset_eval, epochs, batch_size, learning_rate, save_path, log_dir, dataset_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea645ba6-7755-4e7b-b789-7d79fa0ecbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = [dataset_path1,dataset_path2,dataset_path3,dataset_path4,dataset_path5]\n",
    "#dataset_paths = [dataset_path1, dataset_path2, dataset_path3]\n",
    "dataset = SegmentationDataset(dataset_paths)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_path_eval = [val_path1]\n",
    "dataset_eval = SegmentationDataset(dataset_path_eval)\n",
    "dataloader_eval = torch.utils.data.DataLoader(dataset_eval, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = load_model()\n",
    "train_segmentation_network(model, dataset, dataset_eval, epochs, batch_size, learning_rate, save_path, log_dir, dataset_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d490cc4-184e-4653-81df-841f9b3d1624",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = [dataset_path1,dataset_path2,dataset_path3,dataset_path4,dataset_path5,dataset_path6]\n",
    "#dataset_paths = [dataset_path1, dataset_path2, dataset_path3]\n",
    "dataset = SegmentationDataset(dataset_paths)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_path_eval = [val_path1]\n",
    "dataset_eval = SegmentationDataset(dataset_path_eval)\n",
    "dataloader_eval = torch.utils.data.DataLoader(dataset_eval, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = load_model()\n",
    "train_segmentation_network(model, dataset, dataset_eval, epochs, batch_size, learning_rate, save_path, log_dir, dataset_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71765c2-cb83-436f-b79b-2e358637eace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval(model,dataloader_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0022f9a3-c81d-4886-8aef-bc122448a46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ptflops import get_model_complexity_info\n",
    "# Get a sample input from the dataloader\n",
    "#sample_input, _ = next(iter(dataloader))\n",
    "#input_size = tuple(sample_input.shape[1:])  # Get the input size\n",
    "\n",
    "# Compute the FLOPs of your model\n",
    "#flops, params = get_model_complexity_info(model, input_size)\n",
    "#gflops = flops / 1e9  # Convert FLOPs to GFLOPs\n",
    "\n",
    "# Log the GFLOPs\n",
    "#print(f\"GFLOPs: {gflops} billion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9d9191-2de4-4baf-9ded-132bd0032a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "\n",
    "# Load the model\n",
    "#model = torch.load(save_path)\n",
    "\n",
    "# Set the model to the device (CPU or GPU)\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model = model.to(device)\n",
    "\n",
    "#test_segmentation_network(model, dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
